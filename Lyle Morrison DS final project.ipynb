{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = pd.read_csv(r'C:/Users/morrison/Desktop/Search Term Final Project/Search Term Final Project Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Total Unique Searches</th>\n",
       "      <th>Search Depth</th>\n",
       "      <th>Time after Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advisors</td>\n",
       "      <td>20180416</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>244.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiduciary asset sizing</td>\n",
       "      <td>20180601</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>c5efcf93-2c56-e711-8107-5065f38afab1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>360.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intermediary distribution</td>\n",
       "      <td>20180405</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>U001BHX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investor segmentation</td>\n",
       "      <td>20180611</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>U001COK</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- The Next Generation of Planning</td>\n",
       "      <td>20180530</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Search Term      Date  Hour  Minute  \\\n",
       "0                           Advisors  20180416     6      26   \n",
       "1             fiduciary asset sizing  20180601    16      37   \n",
       "2          intermediary distribution  20180405    13      12   \n",
       "3              investor segmentation  20180611     4      32   \n",
       "4  - The Next Generation of Planning  20180530    11       1   \n",
       "\n",
       "                                User ID  Total Unique Searches  Search Depth  \\\n",
       "0                        Anonymous-User                      2             0   \n",
       "1  c5efcf93-2c56-e711-8107-5065f38afab1                      2             0   \n",
       "2                               U001BHX                      2             0   \n",
       "3                               U001COK                      2             3   \n",
       "4                        Anonymous-User                      1             1   \n",
       "\n",
       "   Time after Search  \n",
       "0              244.5  \n",
       "1              360.5  \n",
       "2              119.5  \n",
       "3              140.0  \n",
       "4               33.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search Term               object\n",
       "Date                       int64\n",
       "Hour                       int64\n",
       "Minute                     int64\n",
       "User ID                   object\n",
       "Total Unique Searches      int64\n",
       "Search Depth               int64\n",
       "Time after Search        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Total Unique Searches</th>\n",
       "      <th>Search Depth</th>\n",
       "      <th>Time after Search</th>\n",
       "      <th>UserID</th>\n",
       "      <th>terms</th>\n",
       "      <th>user_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advisors</td>\n",
       "      <td>20180416</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>244.5</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>Advisors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiduciary asset sizing</td>\n",
       "      <td>20180601</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>c5efcf93-2c56-e711-8107-5065f38afab1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>360.5</td>\n",
       "      <td>c5efcf93-2c56-e711-8107-5065f38afab1</td>\n",
       "      <td>fiduciary asset sizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intermediary distribution</td>\n",
       "      <td>20180405</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>U001BHX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119.5</td>\n",
       "      <td>U001BHX</td>\n",
       "      <td>intermediary distribution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>investor segmentation</td>\n",
       "      <td>20180611</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>U001COK</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>U001COK</td>\n",
       "      <td>investor segmentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- The Next Generation of Planning</td>\n",
       "      <td>20180530</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Anonymous-User</td>\n",
       "      <td>- The Next Generation of Planning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Search Term      Date  Hour  Minute  \\\n",
       "0                           Advisors  20180416     6      26   \n",
       "1             fiduciary asset sizing  20180601    16      37   \n",
       "2          intermediary distribution  20180405    13      12   \n",
       "3              investor segmentation  20180611     4      32   \n",
       "4  - The Next Generation of Planning  20180530    11       1   \n",
       "\n",
       "                                User ID  Total Unique Searches  Search Depth  \\\n",
       "0                        Anonymous-User                      2             0   \n",
       "1  c5efcf93-2c56-e711-8107-5065f38afab1                      2             0   \n",
       "2                               U001BHX                      2             0   \n",
       "3                               U001COK                      2             3   \n",
       "4                        Anonymous-User                      1             1   \n",
       "\n",
       "   Time after Search                                UserID  \\\n",
       "0              244.5                        Anonymous-User   \n",
       "1              360.5  c5efcf93-2c56-e711-8107-5065f38afab1   \n",
       "2              119.5                               U001BHX   \n",
       "3              140.0                               U001COK   \n",
       "4               33.0                        Anonymous-User   \n",
       "\n",
       "                               terms  user_not  \n",
       "0                           Advisors         0  \n",
       "1             fiduciary asset sizing         1  \n",
       "2          intermediary distribution         1  \n",
       "3              investor segmentation         1  \n",
       "4  - The Next Generation of Planning         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create binary user ID variable\n",
    "#users with a weird looking string are existing clients in our system\n",
    "#users with 'Anonymous-User' are not in our system\n",
    "#existing users == 1 | unknown/new users == 0\n",
    "search_terms['UserID'] = search_terms['User ID']\n",
    "search_terms['terms'] = search_terms['Search Term']\n",
    "search_terms['user_not'] = search_terms.UserID.map(lambda x: 0 if x == 'Anonymous-User' else 1)\n",
    "search_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Date</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hour</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Time after Search</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Total Unique Searches</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_not</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934.0</td>\n",
       "      <td>2.018052e+07</td>\n",
       "      <td>83.338857</td>\n",
       "      <td>20180401.0</td>\n",
       "      <td>20180423.0</td>\n",
       "      <td>20180515.0</td>\n",
       "      <td>20180611.0</td>\n",
       "      <td>20180629.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>12.109100</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2557.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>0.945708</td>\n",
       "      <td>0.228922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3569.0</td>\n",
       "      <td>2.018052e+07</td>\n",
       "      <td>81.615259</td>\n",
       "      <td>20180401.0</td>\n",
       "      <td>20180425.0</td>\n",
       "      <td>20180518.0</td>\n",
       "      <td>20180608.0</td>\n",
       "      <td>20180630.0</td>\n",
       "      <td>3569.0</td>\n",
       "      <td>12.516391</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3293.0</td>\n",
       "      <td>3569.0</td>\n",
       "      <td>0.922387</td>\n",
       "      <td>0.270723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                                               \\\n",
       "           count          mean        std         min         25%         50%   \n",
       "user_not                                                                        \n",
       "0         1934.0  2.018052e+07  83.338857  20180401.0  20180423.0  20180515.0   \n",
       "1         3569.0  2.018052e+07  81.615259  20180401.0  20180425.0  20180518.0   \n",
       "\n",
       "                                    Hour            ...  Time after Search  \\\n",
       "                 75%         max   count       mean ...                75%   \n",
       "user_not                                            ...                      \n",
       "0         20180611.0  20180629.0  1934.0  12.109100 ...               63.0   \n",
       "1         20180608.0  20180630.0  3569.0  12.516391 ...              148.0   \n",
       "\n",
       "                 Total Unique Searches                                     \\\n",
       "             max                 count      mean       std  min  25%  50%   \n",
       "user_not                                                                    \n",
       "0         2557.0                1934.0  0.945708  0.228922  0.0  1.0  1.0   \n",
       "1         3293.0                3569.0  0.922387  0.270723  0.0  1.0  1.0   \n",
       "\n",
       "                    \n",
       "          75%  max  \n",
       "user_not            \n",
       "0         1.0  2.0  \n",
       "1         1.0  2.0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms.groupby(by='user_not').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING TERM VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining features and target variables\n",
    "X = search_terms.terms\n",
    "y = search_terms.user_not\n",
    "\n",
    "#split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams: 1\n",
      "count vector accuracy: 0.6736918604651163\n",
      "ngrams: 2\n",
      "count vector accuracy: 0.6729651162790697\n",
      "ngrams: 3\n",
      "count vector accuracy: 0.6729651162790697\n",
      "ngrams: 4\n",
      "count vector accuracy: 0.6722383720930233\n",
      "ngrams: 5\n",
      "count vector accuracy: 0.6722383720930233\n",
      "ngrams: 6\n",
      "count vector accuracy: 0.6744186046511628\n",
      "ngrams: 7\n",
      "count vector accuracy: 0.6722383720930233\n",
      "ngrams: 8\n",
      "count vector accuracy: 0.6715116279069767\n",
      "ngrams: 9\n",
      "count vector accuracy: 0.6722383720930233\n"
     ]
    }
   ],
   "source": [
    "#count vector\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "cnt_top_terms = []\n",
    "cnt_ngrams = []\n",
    "for k in range(1,10):\n",
    "    print('ngrams: ' + str(k))\n",
    "    cnt_vect = CountVectorizer(stop_words='english', max_features=1000, ngram_range=(1,k), min_df=2)\n",
    "    X_train_cnt = cnt_vect.fit_transform(X_train)\n",
    "    X_test_cnt = cnt_vect.transform(X_test)\n",
    "    \n",
    "    #count vector\n",
    "    nb.fit(X_train_cnt, y_train)\n",
    "    y_pred_class_cnt = nb.predict(X_test_cnt)\n",
    "\n",
    "    #calculating accuracy.\n",
    "    print('count vector accuracy: ' + str(metrics.accuracy_score(y_test, y_pred_class_cnt)))\n",
    "    cnt_ngrams.append(metrics.accuracy_score(y_test, y_pred_class_cnt))\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "#creates a list of the top terms\n",
    "cnt_top_terms.append(tfidf_tf.sum)\n",
    "tfidf_top_terms.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams: 1\n",
      "tf-idf vector accuracy: 0.6751453488372093\n",
      "ngrams: 2\n",
      "tf-idf vector accuracy: 0.6896802325581395\n",
      "ngrams: 3\n",
      "tf-idf vector accuracy: 0.6853197674418605\n",
      "ngrams: 4\n",
      "tf-idf vector accuracy: 0.6831395348837209\n",
      "ngrams: 5\n",
      "tf-idf vector accuracy: 0.6816860465116279\n",
      "ngrams: 6\n",
      "tf-idf vector accuracy: 0.6838662790697675\n",
      "ngrams: 7\n",
      "tf-idf vector accuracy: 0.6838662790697675\n",
      "ngrams: 8\n",
      "tf-idf vector accuracy: 0.6838662790697675\n",
      "ngrams: 9\n",
      "tf-idf vector accuracy: 0.6831395348837209\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-53a63a7a1ca2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#creates a list of the top terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtf_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mtfidf_top_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtfidf_top_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 266\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "#tdif vector\n",
    "tfidf_top_terms = []\n",
    "tfidf_ngrams = []\n",
    "for k in range(1,10):\n",
    "    print('ngrams: ' + str(k))\n",
    "    tfidf_vect = TfidfVectorizer(stop_words='english', max_features=1000, ngram_range=(1,k), min_df=2)\n",
    "    X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "    \n",
    "    #count vector\n",
    "    nb.fit(X_train_tfidf, y_train)\n",
    "    y_pred_class_tfidf = nb.predict(X_test_tfidf)\n",
    "\n",
    "    #calculating accuracy.\n",
    "    print('tf-idf vector accuracy: ' + str(metrics.accuracy_score(y_test, y_pred_class_tfidf)))\n",
    "    tfidf_ngrams.append(metrics.accuracy_score(y_test, y_pred_class_tfidf))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams: 1\n",
      "tfidf + features accuracy: 0.7020348837209303\n",
      "ngrams: 2\n",
      "tfidf + features accuracy: 0.6947674418604651\n",
      "ngrams: 3\n",
      "tfidf + features accuracy: 0.6875\n",
      "ngrams: 4\n",
      "tfidf + features accuracy: 0.690406976744186\n",
      "ngrams: 5\n",
      "tfidf + features accuracy: 0.6882267441860465\n",
      "ngrams: 6\n",
      "tfidf + features accuracy: 0.688953488372093\n",
      "ngrams: 7\n",
      "tfidf + features accuracy: 0.690406976744186\n",
      "ngrams: 8\n",
      "tfidf + features accuracy: 0.6867732558139535\n",
      "ngrams: 9\n",
      "tfidf + features accuracy: 0.690406976744186\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "\n",
    "feature_cols = ['terms', 'Search Depth', 'Time after Search']\n",
    "X2 = search_terms[feature_cols]\n",
    "y2 = search_terms.user_not\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state=1)\n",
    "\n",
    "# Use CountVectorizer with text column only.\n",
    "\n",
    "for k in range(1,10):\n",
    "    print('ngrams: ' + str(k))\n",
    "    vect = TfidfVectorizer(ngram_range = (1,k))\n",
    "    X_train_extra = vect.fit_transform(X_train.terms)\n",
    "    X_test_extra = vect.transform(X_test.terms)\n",
    "\n",
    "    # Cast other feature columns to float and convert to a sparse matrix.\n",
    "    extra = sp.sparse.csr_matrix(X_train.drop('terms', axis=1).astype(float))\n",
    "\n",
    "\n",
    "    # Combine sparse matrices.\n",
    "    X_train_dtm_extra = sp.sparse.hstack((X_train_extra, extra))\n",
    "\n",
    "\n",
    "    # Repeat for testing set.\n",
    "    extra = sp.sparse.csr_matrix(X_test.drop('terms', axis=1).astype(float))\n",
    "    X_test_dtm_extra = sp.sparse.hstack((X_test_extra, extra))\n",
    "\n",
    "    # Use logistic regression with all features.\n",
    "    logreg = LogisticRegression(C=1e9)\n",
    "    logreg.fit(X_train_dtm_extra, y_train)\n",
    "    y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "    print('tfidf + features accuracy: ' + str(metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b3f68e771d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train_extra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test_extra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Cast other feature columns to float and convert to a sparse matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(ngram_range = (1,k))\n",
    "X_train_extra = vect.fit_transform(X_train.terms)\n",
    "X_test_extra = vect.transform(X_test.terms)\n",
    "\n",
    "# Cast other feature columns to float and convert to a sparse matrix.\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('terms', axis=1).astype(float))\n",
    "\n",
    "\n",
    "# Combine sparse matrices.\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_extra, extra))\n",
    "\n",
    "\n",
    "# Repeat for testing set.\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('terms', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_extra, extra))\n",
    "\n",
    "# Use logistic regression with all features.\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "featuresplus = metrics.accuracy_score(y_test, y_pred_class)\n",
    "\n",
    "\n",
    "#creates a list of the top terms\n",
    "featuresplus_top_terms = []\n",
    "featuresplus = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names())\n",
    "featuresplus_top_terms.append(cnt_tf.sum)\n",
    "featuresplus_top_terms.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE MODEL\n",
    "\n",
    "I am going to use a simple probability based upon the percentage of users compared to non-users as the baseline by which to measure the accuracy of subsequent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6485553334544794\n"
     ]
    }
   ],
   "source": [
    "baseline_model = search_terms['user_not'].sum() / search_terms.user_not.count()\n",
    "print(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count vector accuracy: 0.6744186046511628\n",
      "Tf-IDF accuracy: 0.6896802325581395\n",
      "-------------------------------------------\n",
      "baseline model : 0.6485553334544794\n"
     ]
    }
   ],
   "source": [
    "#using Naive Bayes to predict users vs nonusers\n",
    "nb = MultinomialNB()\n",
    "\n",
    "#count vector\n",
    "cnt_vect = CountVectorizer(stop_words='english', max_features=1000, ngram_range=(1,6), min_df=2)\n",
    "X_train_cnt = cnt_vect.fit_transform(X_train)\n",
    "X_test_cnt = cnt_vect.transform(X_test)\n",
    "\n",
    "nb.fit(X_train_cnt, y_train)\n",
    "y_pred_class_cnt = nb.predict(X_test_cnt)\n",
    "\n",
    "#calculating accuracy.\n",
    "print('count vector accuracy: ' + str(metrics.accuracy_score(y_test, y_pred_class_cnt)))\n",
    "\n",
    "#creates a list of the top terms\n",
    "cnt_top_terms = []\n",
    "cnt_tf = pd.DataFrame(cnt_vect.fit_transform(X_train).toarray(), columns=cnt_vect.get_feature_names())\n",
    "cnt_top_terms.append(cnt_tf.sum)\n",
    "cnt_top_terms.sort()\n",
    "\n",
    "\n",
    "#tfidf vector\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=1000, ngram_range=(1,2), min_df=2)\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "    \n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred_class_tfidf = nb.predict(X_test_tfidf)\n",
    "\n",
    "#calculating accuracy.\n",
    "print('Tf-IDF accuracy: '+ str(metrics.accuracy_score(y_test, y_pred_class_tfidf)))\n",
    "\n",
    "#creates a list of the top terms\n",
    "tfidf_top_terms = []\n",
    "tf_idf = pd.DataFrame(tfidf_vect.fit_transform(X_train).toarray(), columns=tfidf_vect.get_feature_names())\n",
    "tfidf_top_terms.append(tf_idf.sum)\n",
    "tfidf_top_terms.sort()\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print('baseline model : ' + str(baseline_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management                                         183\n",
       "asset                                              170\n",
       "advisor                                            118\n",
       "distribution                                       117\n",
       "managed                                            115\n",
       "retail                                             108\n",
       "retirement                                         106\n",
       "wealth                                             102\n",
       "institutional                                       98\n",
       "asset management                                    91\n",
       "european                                            84\n",
       "ria                                                 83\n",
       "financial                                           80\n",
       "product                                             79\n",
       "fund                                                75\n",
       "asia                                                75\n",
       "accounts                                            75\n",
       "markets                                             74\n",
       "2017                                                71\n",
       "esg                                                 70\n",
       "investor                                            69\n",
       "assets                                              68\n",
       "account                                             66\n",
       "managed accounts                                    63\n",
       "etf                                                 62\n",
       "dynamics                                            61\n",
       "insurance                                           58\n",
       "distribution dynamics                               56\n",
       "defined                                             52\n",
       "portfolio                                           52\n",
       "                                                  ... \n",
       "retirement market size                               2\n",
       "product usage 2011                                   2\n",
       "product trends 2018                                  2\n",
       "retial investor advice                               2\n",
       "spend                                                2\n",
       "retirement income products                           2\n",
       "strategic                                            2\n",
       "status                                               2\n",
       "product development 2017 advisor                     2\n",
       "standard                                             2\n",
       "stable value                                         2\n",
       "stable                                               2\n",
       "product development 2017 advisor product             2\n",
       "product development 2017 advisor product demand      2\n",
       "spend time clients                                   2\n",
       "spend time                                           2\n",
       "space                                                2\n",
       "service providers                                    2\n",
       "sovereign wealth funds                               2\n",
       "product development model                            2\n",
       "southeast asia 2015                                  2\n",
       "south africa                                         2\n",
       "source                                               2\n",
       "solvency                                             2\n",
       "social                                               2\n",
       "product development model driven                     2\n",
       "shape                                                2\n",
       "services cost                                        2\n",
       "product penetration                                  2\n",
       "spend time clients value                             2\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_top_terms = cnt_tf.sum()\n",
    "cnt_top_terms.sort_values(ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Total Unique Searches</th>\n",
       "      <th>Search Depth</th>\n",
       "      <th>Time after Search</th>\n",
       "      <th>20</th>\n",
       "      <th>20 digital</th>\n",
       "      <th>2011</th>\n",
       "      <th>2015</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>worth markets</th>\n",
       "      <th>worth markets 2016</th>\n",
       "      <th>worth ultra</th>\n",
       "      <th>worth ultra high</th>\n",
       "      <th>worth ultra high net</th>\n",
       "      <th>worth ultra high net worth</th>\n",
       "      <th>worth ultra high net worth markets</th>\n",
       "      <th>year</th>\n",
       "      <th>year review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_not</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53922345848</td>\n",
       "      <td>33328</td>\n",
       "      <td>81972</td>\n",
       "      <td>2675</td>\n",
       "      <td>2773</td>\n",
       "      <td>555480.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date   Hour  Minute  Total Unique Searches  Search Depth  \\\n",
       "user_not                                                                    \n",
       "1         53922345848  33328   81972                   2675          2773   \n",
       "\n",
       "          Time after Search  20  20 digital  2011  2015     ...       worth  \\\n",
       "user_not                                                    ...               \n",
       "1                  555480.0   2           2     3     8     ...          23   \n",
       "\n",
       "          worth markets  worth markets 2016  worth ultra  worth ultra high  \\\n",
       "user_not                                                                     \n",
       "1                     5                   2            5                 5   \n",
       "\n",
       "          worth ultra high net  worth ultra high net worth  \\\n",
       "user_not                                                     \n",
       "1                            5                           5   \n",
       "\n",
       "          worth ultra high net worth markets  year  year review  \n",
       "user_not                                                         \n",
       "1                                          5     3            3  \n",
       "\n",
       "[1 rows x 1006 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top terms for users vs nonusers for COUNT vector\n",
    "cnt_merged_terms = pd.merge(search_terms, cnt_tf, left_index=True, right_index=True)\n",
    "cnt_merged_terms_SORT = cnt_merged_terms.groupby(by='user_not').sum()\n",
    "#cnt_merged_terms_SORT\n",
    "\n",
    "cnt_merged_terms_SORT_USERS = cnt_merged_terms_SORT.iloc[[0]]\n",
    "cnt_merged_terms_SORT_USERS\n",
    "\n",
    "cnt_merged_terms_SORT_NONUSERS = cnt_merged_terms_SORT.iloc[[1]]\n",
    "cnt_merged_terms_SORT_NONUSERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                5.392235e+10\n",
       "Time after Search                   5.554800e+05\n",
       "Minute                              8.197200e+04\n",
       "Hour                                3.332800e+04\n",
       "Search Depth                        2.773000e+03\n",
       "Total Unique Searches               2.675000e+03\n",
       "management                          1.350000e+02\n",
       "asset                               1.170000e+02\n",
       "advisor                             9.400000e+01\n",
       "managed                             7.700000e+01\n",
       "wealth                              7.600000e+01\n",
       "retirement                          7.200000e+01\n",
       "distribution                        6.900000e+01\n",
       "retail                              6.900000e+01\n",
       "asset management                    6.900000e+01\n",
       "institutional                       6.100000e+01\n",
       "european                            5.300000e+01\n",
       "accounts                            5.000000e+01\n",
       "investor                            4.900000e+01\n",
       "asia                                4.900000e+01\n",
       "markets                             4.800000e+01\n",
       "financial                           4.700000e+01\n",
       "esg                                 4.600000e+01\n",
       "etf                                 4.600000e+01\n",
       "fund                                4.600000e+01\n",
       "product                             4.500000e+01\n",
       "account                             4.500000e+01\n",
       "assets                              4.500000e+01\n",
       "ria                                 4.500000e+01\n",
       "2017                                4.500000e+01\n",
       "                                        ...     \n",
       "sponsor                             1.000000e+00\n",
       "retial investor advice              1.000000e+00\n",
       "bank channel assets segment         1.000000e+00\n",
       "bank channel assets                 1.000000e+00\n",
       "bank channel                        1.000000e+00\n",
       "organizations                       1.000000e+00\n",
       "saving                              1.000000e+00\n",
       "asset management australia          1.000000e+00\n",
       "satisfaction                        1.000000e+00\n",
       "switzerland                         1.000000e+00\n",
       "ppa                                 1.000000e+00\n",
       "financial professionals             1.000000e+00\n",
       "assets segment                      1.000000e+00\n",
       "equities                            0.000000e+00\n",
       "product trends 2018                 0.000000e+00\n",
       "google                              0.000000e+00\n",
       "maturity                            0.000000e+00\n",
       "relationship manager                0.000000e+00\n",
       "status                              0.000000e+00\n",
       "lodestar                            0.000000e+00\n",
       "sclafani                            0.000000e+00\n",
       "wholesalers                         0.000000e+00\n",
       "practice management resources       0.000000e+00\n",
       "weekly conversations wholesalers    0.000000e+00\n",
       "weekly conversations                0.000000e+00\n",
       "weekly                              0.000000e+00\n",
       "retirement plan                     0.000000e+00\n",
       "programs                            0.000000e+00\n",
       "space                               0.000000e+00\n",
       "australia 2017                      0.000000e+00\n",
       "Length: 1006, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligma1 = cnt_merged_terms_SORT_NONUSERS.sum()\n",
    "ligma1.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                          2.936265e+10\n",
       "Time after Search                             1.776105e+05\n",
       "Minute                                        4.496200e+04\n",
       "Hour                                          1.748700e+04\n",
       "Search Depth                                  1.938000e+03\n",
       "Total Unique Searches                         1.456000e+03\n",
       "asset                                         5.300000e+01\n",
       "management                                    4.800000e+01\n",
       "distribution                                  4.800000e+01\n",
       "retail                                        3.900000e+01\n",
       "managed                                       3.800000e+01\n",
       "ria                                           3.800000e+01\n",
       "institutional                                 3.700000e+01\n",
       "retirement                                    3.400000e+01\n",
       "product                                       3.400000e+01\n",
       "financial                                     3.300000e+01\n",
       "european                                      3.100000e+01\n",
       "fund                                          2.900000e+01\n",
       "asia                                          2.600000e+01\n",
       "wealth                                        2.600000e+01\n",
       "markets                                       2.600000e+01\n",
       "2017                                          2.600000e+01\n",
       "accounts                                      2.500000e+01\n",
       "advisor                                       2.400000e+01\n",
       "esg                                           2.400000e+01\n",
       "advisors                                      2.400000e+01\n",
       "assets                                        2.300000e+01\n",
       "portfolio                                     2.200000e+01\n",
       "global                                        2.200000e+01\n",
       "asset management                              2.200000e+01\n",
       "                                                  ...     \n",
       "assets channel                                0.000000e+00\n",
       "asset wealth                                  0.000000e+00\n",
       "asset management opportunities                0.000000e+00\n",
       "asset management middle east                  0.000000e+00\n",
       "risk market                                   0.000000e+00\n",
       "breakaway                                     0.000000e+00\n",
       "rise                                          0.000000e+00\n",
       "review                                        0.000000e+00\n",
       "product rationalization                       0.000000e+00\n",
       "product trend                                 0.000000e+00\n",
       "product usage 2011                            0.000000e+00\n",
       "custody                                       0.000000e+00\n",
       "ranking                                       0.000000e+00\n",
       "rationalization                               0.000000e+00\n",
       "consumers                                     0.000000e+00\n",
       "retail assets                                 0.000000e+00\n",
       "retail institutional asset management 2017    0.000000e+00\n",
       "retail investor product                       0.000000e+00\n",
       "retail investor product usage                 0.000000e+00\n",
       "retail investor product usage 2011            0.000000e+00\n",
       "closed end funds                              0.000000e+00\n",
       "closed end                                    0.000000e+00\n",
       "headcount                                     0.000000e+00\n",
       "clients value                                 0.000000e+00\n",
       "client acquisition                            0.000000e+00\n",
       "retirees                                      0.000000e+00\n",
       "challenges                                    0.000000e+00\n",
       "retirement market size                        0.000000e+00\n",
       "retirement services                           0.000000e+00\n",
       "year review                                   0.000000e+00\n",
       "Length: 1006, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligma = cnt_merged_terms_SORT_USERS.sum()\n",
    "ligma.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management                   72.827455\n",
       "ria                          66.116057\n",
       "asset                        65.060808\n",
       "retirement                   63.329714\n",
       "esg                          62.366235\n",
       "advisor                      59.543192\n",
       "institutional                59.291170\n",
       "etf                          57.952796\n",
       "distribution                 56.797682\n",
       "managed                      55.131930\n",
       "wealth                       53.338771\n",
       "retail                       46.949740\n",
       "product                      43.743210\n",
       "asia                         39.837028\n",
       "accounts                     39.277341\n",
       "asset management             39.066848\n",
       "ocio                         37.948158\n",
       "robo                         37.728502\n",
       "insurance                    36.781920\n",
       "european                     36.332395\n",
       "financial                    35.650657\n",
       "managed accounts             34.901497\n",
       "fund                         34.852919\n",
       "global                       33.517520\n",
       "account                      33.511952\n",
       "assets                       33.469193\n",
       "markets                      32.174157\n",
       "japan                        31.117567\n",
       "investor                     30.979035\n",
       "intermediary                 30.974320\n",
       "                               ...    \n",
       "implementing customized       0.740358\n",
       "implementing                  0.740358\n",
       "services client               0.740358\n",
       "strategies implementing       0.740358\n",
       "2017 identifying              0.738545\n",
       "usage 2011                    0.730214\n",
       "report retail                 0.728115\n",
       "cost equivalent               0.716623\n",
       "low cost                      0.716623\n",
       "equivalent                    0.716623\n",
       "equivalent low                0.716623\n",
       "low risk                      0.716623\n",
       "advisers spend                0.714123\n",
       "spend                         0.714123\n",
       "spend time                    0.714123\n",
       "skeptical                     0.688321\n",
       "provide holistic              0.620502\n",
       "provide                       0.620502\n",
       "38 financial                  0.620502\n",
       "advisor product               0.556893\n",
       "development 2017              0.556893\n",
       "demand model                  0.556893\n",
       "risk market                   0.422247\n",
       "unfortunate misconception     0.422247\n",
       "fiduciary perspective         0.422247\n",
       "fiduciaries low               0.422247\n",
       "fiduciaries                   0.422247\n",
       "exists defined                0.422247\n",
       "unfortunate                   0.422247\n",
       "exists                        0.422247\n",
       "Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms_tfidf = tf_idf.sum()\n",
    "top_terms_tfidf.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Total Unique Searches</th>\n",
       "      <th>Search Depth</th>\n",
       "      <th>Time after Search</th>\n",
       "      <th>20</th>\n",
       "      <th>20 digital</th>\n",
       "      <th>2011</th>\n",
       "      <th>2015</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>worth markets</th>\n",
       "      <th>worth markets 2016</th>\n",
       "      <th>worth ultra</th>\n",
       "      <th>worth ultra high</th>\n",
       "      <th>worth ultra high net</th>\n",
       "      <th>worth ultra high net worth</th>\n",
       "      <th>worth ultra high net worth markets</th>\n",
       "      <th>year</th>\n",
       "      <th>year review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_not</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53922345848</td>\n",
       "      <td>33328</td>\n",
       "      <td>81972</td>\n",
       "      <td>2675</td>\n",
       "      <td>2773</td>\n",
       "      <td>555480.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date   Hour  Minute  Total Unique Searches  Search Depth  \\\n",
       "user_not                                                                    \n",
       "1         53922345848  33328   81972                   2675          2773   \n",
       "\n",
       "          Time after Search  20  20 digital  2011  2015     ...       worth  \\\n",
       "user_not                                                    ...               \n",
       "1                  555480.0   2           2     3     8     ...          23   \n",
       "\n",
       "          worth markets  worth markets 2016  worth ultra  worth ultra high  \\\n",
       "user_not                                                                     \n",
       "1                     5                   2            5                 5   \n",
       "\n",
       "          worth ultra high net  worth ultra high net worth  \\\n",
       "user_not                                                     \n",
       "1                            5                           5   \n",
       "\n",
       "          worth ultra high net worth markets  year  year review  \n",
       "user_not                                                         \n",
       "1                                          5     3            3  \n",
       "\n",
       "[1 rows x 1006 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top terms for users vs nonusers for tfidf vector\n",
    "tfidf_merged_terms = pd.merge(search_terms, tf_idf, left_index=True, right_index=True)\n",
    "tfidf_merged_terms_SORT = tfidf_merged_terms.groupby(by='user_not').sum()\n",
    "#cnt_merged_terms_SORT\n",
    "\n",
    "tfidf_merged_terms_SORT_USERS = cnt_merged_terms_SORT.iloc[[0]]\n",
    "tfidf_merged_terms_SORT_USERS\n",
    "\n",
    "tfidf_merged_terms_SORT_NONUSERS = cnt_merged_terms_SORT.iloc[[1]]\n",
    "tfidf_merged_terms_SORT_NONUSERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                          2.936265e+10\n",
       "Time after Search                             1.776105e+05\n",
       "Minute                                        4.496200e+04\n",
       "Hour                                          1.748700e+04\n",
       "Search Depth                                  1.938000e+03\n",
       "Total Unique Searches                         1.456000e+03\n",
       "asset                                         5.300000e+01\n",
       "management                                    4.800000e+01\n",
       "distribution                                  4.800000e+01\n",
       "retail                                        3.900000e+01\n",
       "managed                                       3.800000e+01\n",
       "ria                                           3.800000e+01\n",
       "institutional                                 3.700000e+01\n",
       "retirement                                    3.400000e+01\n",
       "product                                       3.400000e+01\n",
       "financial                                     3.300000e+01\n",
       "european                                      3.100000e+01\n",
       "fund                                          2.900000e+01\n",
       "asia                                          2.600000e+01\n",
       "wealth                                        2.600000e+01\n",
       "markets                                       2.600000e+01\n",
       "2017                                          2.600000e+01\n",
       "accounts                                      2.500000e+01\n",
       "advisor                                       2.400000e+01\n",
       "esg                                           2.400000e+01\n",
       "advisors                                      2.400000e+01\n",
       "assets                                        2.300000e+01\n",
       "portfolio                                     2.200000e+01\n",
       "global                                        2.200000e+01\n",
       "asset management                              2.200000e+01\n",
       "                                                  ...     \n",
       "assets channel                                0.000000e+00\n",
       "asset wealth                                  0.000000e+00\n",
       "asset management opportunities                0.000000e+00\n",
       "asset management middle east                  0.000000e+00\n",
       "risk market                                   0.000000e+00\n",
       "breakaway                                     0.000000e+00\n",
       "rise                                          0.000000e+00\n",
       "review                                        0.000000e+00\n",
       "product rationalization                       0.000000e+00\n",
       "product trend                                 0.000000e+00\n",
       "product usage 2011                            0.000000e+00\n",
       "custody                                       0.000000e+00\n",
       "ranking                                       0.000000e+00\n",
       "rationalization                               0.000000e+00\n",
       "consumers                                     0.000000e+00\n",
       "retail assets                                 0.000000e+00\n",
       "retail institutional asset management 2017    0.000000e+00\n",
       "retail investor product                       0.000000e+00\n",
       "retail investor product usage                 0.000000e+00\n",
       "retail investor product usage 2011            0.000000e+00\n",
       "closed end funds                              0.000000e+00\n",
       "closed end                                    0.000000e+00\n",
       "headcount                                     0.000000e+00\n",
       "clients value                                 0.000000e+00\n",
       "client acquisition                            0.000000e+00\n",
       "retirees                                      0.000000e+00\n",
       "challenges                                    0.000000e+00\n",
       "retirement market size                        0.000000e+00\n",
       "retirement services                           0.000000e+00\n",
       "year review                                   0.000000e+00\n",
       "Length: 1006, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligma2 = tfidf_merged_terms_SORT_USERS.sum()\n",
    "ligma2.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                5.392235e+10\n",
       "Time after Search                   5.554800e+05\n",
       "Minute                              8.197200e+04\n",
       "Hour                                3.332800e+04\n",
       "Search Depth                        2.773000e+03\n",
       "Total Unique Searches               2.675000e+03\n",
       "management                          1.350000e+02\n",
       "asset                               1.170000e+02\n",
       "advisor                             9.400000e+01\n",
       "managed                             7.700000e+01\n",
       "wealth                              7.600000e+01\n",
       "retirement                          7.200000e+01\n",
       "distribution                        6.900000e+01\n",
       "retail                              6.900000e+01\n",
       "asset management                    6.900000e+01\n",
       "institutional                       6.100000e+01\n",
       "european                            5.300000e+01\n",
       "accounts                            5.000000e+01\n",
       "investor                            4.900000e+01\n",
       "asia                                4.900000e+01\n",
       "markets                             4.800000e+01\n",
       "financial                           4.700000e+01\n",
       "esg                                 4.600000e+01\n",
       "etf                                 4.600000e+01\n",
       "fund                                4.600000e+01\n",
       "product                             4.500000e+01\n",
       "account                             4.500000e+01\n",
       "assets                              4.500000e+01\n",
       "ria                                 4.500000e+01\n",
       "2017                                4.500000e+01\n",
       "                                        ...     \n",
       "sponsor                             1.000000e+00\n",
       "retial investor advice              1.000000e+00\n",
       "bank channel assets segment         1.000000e+00\n",
       "bank channel assets                 1.000000e+00\n",
       "bank channel                        1.000000e+00\n",
       "organizations                       1.000000e+00\n",
       "saving                              1.000000e+00\n",
       "asset management australia          1.000000e+00\n",
       "satisfaction                        1.000000e+00\n",
       "switzerland                         1.000000e+00\n",
       "ppa                                 1.000000e+00\n",
       "financial professionals             1.000000e+00\n",
       "assets segment                      1.000000e+00\n",
       "equities                            0.000000e+00\n",
       "product trends 2018                 0.000000e+00\n",
       "google                              0.000000e+00\n",
       "maturity                            0.000000e+00\n",
       "relationship manager                0.000000e+00\n",
       "status                              0.000000e+00\n",
       "lodestar                            0.000000e+00\n",
       "sclafani                            0.000000e+00\n",
       "wholesalers                         0.000000e+00\n",
       "practice management resources       0.000000e+00\n",
       "weekly conversations wholesalers    0.000000e+00\n",
       "weekly conversations                0.000000e+00\n",
       "weekly                              0.000000e+00\n",
       "retirement plan                     0.000000e+00\n",
       "programs                            0.000000e+00\n",
       "space                               0.000000e+00\n",
       "australia 2017                      0.000000e+00\n",
       "Length: 1006, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligma3 = tfidf_merged_terms_SORT_NONUSERS.sum()\n",
    "ligma3.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLICATION\n",
    "The relevant application is to be able to feed a search query into the model and get back a certain percentage/probability that the searcher is a user or non-user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_query_identifier(query):\n",
    "    nb = MultinomialNB()\n",
    "    tfidf_vect = TfidfVectorizer(stop_words='english', max_features=1000, ngram_range=(1,5), min_df=2)\n",
    "    \n",
    "    X_train_tfidf_app = tfidf_vect.fit_transform(X_train)\n",
    "    X_test_tfidf_app = tfidf_vect.transform(X_test)\n",
    "    \n",
    "    nb.fit(X_train_tfidf_app, y_train)\n",
    "    nb.predict(query)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'advisors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-ff6f212d3f5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_query_identifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'advisors'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-cd84eef41a57>\u001b[0m in \u001b[0;36muser_query_identifier\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0muser_query_identifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'advisors'"
     ]
    }
   ],
   "source": [
    "user_query_identifier('advisors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams: 1\n",
      "tfidf + features accuracy: 0.7020348837209303\n",
      "ngrams: 2\n",
      "tfidf + features accuracy: 0.6947674418604651\n",
      "ngrams: 3\n",
      "tfidf + features accuracy: 0.6875\n",
      "ngrams: 4\n",
      "tfidf + features accuracy: 0.690406976744186\n",
      "ngrams: 5\n",
      "tfidf + features accuracy: 0.6882267441860465\n",
      "ngrams: 6\n",
      "tfidf + features accuracy: 0.688953488372093\n",
      "ngrams: 7\n",
      "tfidf + features accuracy: 0.690406976744186\n",
      "ngrams: 8\n",
      "tfidf + features accuracy: 0.6867732558139535\n",
      "ngrams: 9\n",
      "tfidf + features accuracy: 0.690406976744186\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "\n",
    "feature_cols = ['terms', 'Search Depth', 'Time after Search']\n",
    "X2 = search_terms[feature_cols]\n",
    "y2 = search_terms.user_not\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state=1)\n",
    "\n",
    "# Use CountVectorizer with text column only.\n",
    "\n",
    "for k in range(1,10):\n",
    "    print('ngrams: ' + str(k))\n",
    "    vect = TfidfVectorizer(ngram_range = (1,k))\n",
    "    X_train_extra = vect.fit_transform(X_train.terms)\n",
    "    X_test_extra = vect.transform(X_test.terms)\n",
    "\n",
    "    # Cast other feature columns to float and convert to a sparse matrix.\n",
    "    extra = sp.sparse.csr_matrix(X_train.drop('terms', axis=1).astype(float))\n",
    "\n",
    "\n",
    "    # Combine sparse matrices.\n",
    "    X_train_dtm_extra = sp.sparse.hstack((X_train_extra, extra))\n",
    "\n",
    "\n",
    "    # Repeat for testing set.\n",
    "    extra = sp.sparse.csr_matrix(X_test.drop('terms', axis=1).astype(float))\n",
    "    X_test_dtm_extra = sp.sparse.hstack((X_test_extra, extra))\n",
    "\n",
    "    # Use logistic regression with all features.\n",
    "    logreg = LogisticRegression(C=1e9)\n",
    "    logreg.fit(X_train_dtm_extra, y_train)\n",
    "    y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "    print('tfidf + features accuracy: ' + str(metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4127, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4127, 1339)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 1339)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686046511627907\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf + features accuracy: 0.7020348837209303\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
